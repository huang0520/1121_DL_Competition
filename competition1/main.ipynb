{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Competition 1 Predicting News Popularity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import re\n",
        "from dataclasses import dataclass, asdict\n",
        "import joblib\n",
        "import warnings\n",
        "import mmap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    cross_validate,\n",
        "    HalvingRandomSearchCV,\n",
        ")\n",
        "from sklearn.feature_extraction.text import (\n",
        "    CountVectorizer,\n",
        "    TfidfVectorizer,\n",
        "    HashingVectorizer,\n",
        ")\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import catboost as cb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/matcha0714/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /home/matcha0714/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Some CONSTANTS\n",
        "RANDOM_STATE = 42\n",
        "INPUT_DIR = \"./input/\"\n",
        "OUTPUT_DIR = \"./output/\"\n",
        "MODEL_SAVE_DIR = \"./model_saves/\"\n",
        "\n",
        "# Create directories if not exist\n",
        "if not os.path.exists(INPUT_DIR):\n",
        "    os.makedirs(INPUT_DIR)\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "if not os.path.exists(MODEL_SAVE_DIR):\n",
        "    os.makedirs(MODEL_SAVE_DIR)\n",
        "\n",
        "# Download nltk stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "STOP = stopwords.words(\"english\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# Stop warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input & Output module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "def input(chunksize: int = 1000, val_size: float = 0.2, stream: bool = False):\n",
        "    train_path = os.path.join(INPUT_DIR, \"train.csv\")\n",
        "    test_path = os.path.join(INPUT_DIR, \"test.csv\")\n",
        "\n",
        "    chunksize = (\n",
        "        chunksize if stream else get_file_len(os.path.join(INPUT_DIR, \"train.csv\"))\n",
        "    )\n",
        "\n",
        "    df_test = pd.read_csv(test_path)\n",
        "    x_test = df_test[\"Page content\"]\n",
        "    id_test = df_test[\"Id\"]\n",
        "\n",
        "    @dataclass\n",
        "    class TestSet:\n",
        "        x: pd.Series\n",
        "        id: pd.Series\n",
        "\n",
        "    return_item = (\n",
        "        (get_stream(train_path, chunksize, val_size), TestSet(x_test, id_test))\n",
        "        if stream\n",
        "        else (\n",
        "            next(get_stream(train_path, chunksize, val_size)),\n",
        "            TestSet(x_test, id_test),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return return_item\n",
        "\n",
        "\n",
        "# 用於進行 Out-of-Core learning 時，所使用的 stream generator\n",
        "def get_stream(train_path, chunksize, val_size=0.2):\n",
        "    @dataclass\n",
        "    class Dataset:\n",
        "        x: pd.Series\n",
        "        y: pd.Series\n",
        "\n",
        "    # 將資料依照 validation size 分成 train/validataion\n",
        "    for chunk in pd.read_csv(train_path, chunksize=chunksize):\n",
        "        x = chunk[\"Page content\"]\n",
        "        y = chunk[\"Popularity\"]\n",
        "\n",
        "        yield Dataset(x, y)\n",
        "\n",
        "\n",
        "def get_file_len(path):\n",
        "    # 用於得到檔案的行數\n",
        "    with open(path, \"rb\") as f:\n",
        "        buf = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "        lines = 0\n",
        "        while buf.readline():\n",
        "            lines += 1\n",
        "        buf.close()\n",
        "\n",
        "        # Remove column rows\n",
        "        return lines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def output(id_test: pd.Series, y_pred: np.ndarray):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    output_filename = f\"output_{timestamp}.csv\"\n",
        "    output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
        "\n",
        "    output_df = pd.DataFrame({\"Id\": id_test.ravel(), \"Popularity\": y_pred})\n",
        "    output_df.to_csv(output_path, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Enignnering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_cleaner(self, text: str):\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, \"html.parser\").text\n",
        "\n",
        "    # regex for matching emoticons, keep emoticons, ex: :), :-P, :-D\n",
        "    r = r\"(?::|;|=|X)(?:-)?(?:\\)|\\(|D|P)\"\n",
        "    emoticons = re.findall(r, text)\n",
        "    text = re.sub(r, \"\", text)\n",
        "\n",
        "    # convert to lowercase and append all emoticons behind (with space in between)\n",
        "    # replace('-','') removes nose of emoticons\n",
        "    text = (\n",
        "        re.sub(r\"[\\W]+\", \" \", text.lower()) + \" \" + \" \".join(emoticons).replace(\"-\", \"\")\n",
        "    )\n",
        "    return text\n",
        "\n",
        "\n",
        "def tokenizer(self, text):\n",
        "    text = re.sub(\"([\\w]+)'[\\w]+\", (lambda match_obj: match_obj.group(1)), text)\n",
        "    text = re.sub(\"\\.\", \"\", text)\n",
        "    text = re.sub(\"[^\\w]+\", \" \", text)\n",
        "    wnl = WordNetLemmatizer()\n",
        "    return [wnl.lemmatize(s) for s in re.split(\"\\s+\", text.strip())]\n",
        "\n",
        "\n",
        "def get_title(self, soup_texts):\n",
        "    return pd.DataFrame(\n",
        "        soup_texts.apply(lambda x: x.body.h1.string.strip().lower()).rename(\"title\")\n",
        "    )\n",
        "\n",
        "\n",
        "def get_topic(self, soup_texts):\n",
        "    def helper(text):\n",
        "        a_list = text.body.find(\"footer\", {\"class\": \"article-topics\"}).find_all(\"a\")\n",
        "        topics = [re.sub(\"\\s+\", \"-\", a.string.strip().lower()) for a in a_list]\n",
        "        return \" \".join(topics)\n",
        "\n",
        "    return pd.DataFrame(soup_texts.apply(helper).rename(\"topic\"))\n",
        "\n",
        "\n",
        "def get_datetime(self, soup_texts):\n",
        "    def helper(text):\n",
        "        try:\n",
        "            datetime_str = text.time[\"datetime\"]\n",
        "        except:\n",
        "            datetime_str = \"Thu, 01 Jan 2014 00:00:00 +0000\"\n",
        "\n",
        "        datetime_obj = datetime.datetime.strptime(\n",
        "            datetime_str, \"%a, %d %b %Y %H:%M:%S %z\"\n",
        "        )\n",
        "\n",
        "        return pd.Series(\n",
        "            {\n",
        "                \"year\": datetime_obj.year,\n",
        "                \"month\": datetime_obj.month,\n",
        "                \"day\": datetime_obj.day,\n",
        "                \"hour\": datetime_obj.hour,\n",
        "                \"minute\": datetime_obj.minute,\n",
        "                \"second\": datetime_obj.second,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    return pd.DataFrame(soup_texts.apply(helper))\n",
        "\n",
        "\n",
        "def get_content_length(self, soup_texts):\n",
        "    def helper(text):\n",
        "        content = text.find(\"section\", class_=\"article-content\").get_text()\n",
        "        return len(content)\n",
        "\n",
        "    return pd.DataFrame(soup_texts.apply(helper).rename(\"content_length\"))\n",
        "\n",
        "\n",
        "def vectorize_texts(self, df: pd.DataFrame, vec_idx: list, vectorizer):\n",
        "    additional_dfs = [\n",
        "        pd.DataFrame.sparse.from_spmatrix(vectorizer.fit_transform(df.loc[:, idx]))\n",
        "        for idx in vec_idx\n",
        "    ]\n",
        "\n",
        "    return pd.concat(additional_dfs, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 調用函式\n",
        "\n",
        "用於更輕鬆的調用之後新增的比如：加新特徵或其他前處理的 Function。\n",
        "\n",
        "還有很多要調整。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class FeatureParams:\n",
        "    do_get_title: bool = True\n",
        "    do_get_topic: bool = True\n",
        "    do_get_datetime: bool = True\n",
        "    do_get_content_length: bool = True\n",
        "\n",
        "    vectorizer: str = \"count\"\n",
        "\n",
        "\n",
        "class FeaturePreprocessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        get_title: bool = True,\n",
        "        get_topic: bool = True,\n",
        "        get_datetime: bool = True,\n",
        "        get_content_length: bool = True,\n",
        "    ) -> None:\n",
        "        self.get_title = get_title\n",
        "        self.get_topic = get_topic\n",
        "        self.get_datetime = get_datetime\n",
        "        self.get_content_length = get_content_length\n",
        "\n",
        "    __text_cleaner = text_cleaner\n",
        "    __tokenizer = tokenizer\n",
        "    __get_title = get_title\n",
        "    __get_topic = get_topic\n",
        "    __get_datetime = get_datetime\n",
        "    __get_content_length = get_content_length\n",
        "\n",
        "    def __add_feature(self, original_df, additional_df):\n",
        "        return (\n",
        "            additional_df\n",
        "            if type(original_df) != pd.DataFrame\n",
        "            else pd.concat([original_df, additional_df], axis=1)\n",
        "        )\n",
        "\n",
        "    def __get_feature(self, texts):\n",
        "        df = None\n",
        "        vec_idx = []\n",
        "\n",
        "        soup_texts = texts.apply(lambda x: BeautifulSoup(x, \"html.parser\"))\n",
        "\n",
        "        if self.get_title:\n",
        "            df = self.__add_feature(df, self.__get_title(soup_texts))\n",
        "            vec_idx += [\"title\"]\n",
        "\n",
        "        if self.get_topic:\n",
        "            df = self.__add_feature(df, self.__get_topic(soup_texts))\n",
        "            vec_idx += [\"topic\"]\n",
        "\n",
        "        if self.get_datetime:\n",
        "            df = self.__add_feature(df, self.__get_datetime(soup_texts))\n",
        "\n",
        "        if self.get_content_length:\n",
        "            df = self.__add_feature(df, self.__get_content_length(soup_texts))\n",
        "\n",
        "        print(f\"Features: {df.columns.tolist()}\")\n",
        "\n",
        "        return df, vec_idx\n",
        "\n",
        "    def fit_transform(self, texts_train):\n",
        "        df, vec_idx = self.__get_feature(texts_train)\n",
        "\n",
        "        if len(vec_idx) != 0:\n",
        "            self.trans = ColumnTransformer(\n",
        "                [\n",
        "                    (idx, CountVectorizer(tokenizer=self.__tokenizer), idx)\n",
        "                    for idx in vec_idx\n",
        "                ],\n",
        "                remainder=\"drop\",\n",
        "                sparse_threshold=0.0,\n",
        "            )\n",
        "\n",
        "            addtional_df = pd.DataFrame(self.trans.fit_transform(df))\n",
        "            df = self.__add_feature(df, addtional_df)\n",
        "\n",
        "        return df.drop(columns=vec_idx, inplace=False)\n",
        "\n",
        "    def transform(self, texts):\n",
        "        df, vec_idx = self.__get_feature(texts)\n",
        "\n",
        "        if len(vec_idx) != 0:\n",
        "            additional_df = pd.DataFrame(self.trans.transform(df))\n",
        "            df = self.__add_feature(df, additional_df)\n",
        "\n",
        "        return df.drop(columns=vec_idx, inplace=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features: ['topic', 'year', 'month', 'day', 'hour', 'minute', 'second', 'content_length']\n",
            "Features: ['topic', 'year', 'month', 'day', 'hour', 'minute', 'second', 'content_length']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "      <th>content_length</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>...</th>\n",
              "      <th>9859</th>\n",
              "      <th>9860</th>\n",
              "      <th>9861</th>\n",
              "      <th>9862</th>\n",
              "      <th>9863</th>\n",
              "      <th>9864</th>\n",
              "      <th>9865</th>\n",
              "      <th>9866</th>\n",
              "      <th>9867</th>\n",
              "      <th>9868</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>3591</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "      <td>40</td>\n",
              "      <td>55</td>\n",
              "      <td>1843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>6646</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>50</td>\n",
              "      <td>1821</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>43</td>\n",
              "      <td>8919</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27638</th>\n",
              "      <td>2014</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>1776</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27639</th>\n",
              "      <td>2014</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>1890</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27640</th>\n",
              "      <td>2014</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>13</td>\n",
              "      <td>1274</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27641</th>\n",
              "      <td>2013</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>20</td>\n",
              "      <td>49</td>\n",
              "      <td>16</td>\n",
              "      <td>2657</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27642</th>\n",
              "      <td>2014</td>\n",
              "      <td>10</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>43</td>\n",
              "      <td>3027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27643 rows × 9876 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       year  month  day  hour  minute  second  content_length  0  1  2  ...  \\\n",
              "0      2013      6   19    15       4      30            3591  0  0  0  ...   \n",
              "1      2013      3   28    17      40      55            1843  0  0  0  ...   \n",
              "2      2014      5    7    19      15      20            6646  0  0  0  ...   \n",
              "3      2013     10   11     2      26      50            1821  0  0  0  ...   \n",
              "4      2014      4   17     3      31      43            8919  0  0  0  ...   \n",
              "...     ...    ...  ...   ...     ...     ...             ... .. .. ..  ...   \n",
              "27638  2014      4    8    16      26      31            1776  0  0  0  ...   \n",
              "27639  2014      7    9     1       3      24            1890  0  0  0  ...   \n",
              "27640  2014      7   10    12      30      13            1274  0  0  0  ...   \n",
              "27641  2013      4   16    20      49      16            2657  0  0  0  ...   \n",
              "27642  2014     10   17    18      22      43            3027  0  0  0  ...   \n",
              "\n",
              "       9859  9860  9861  9862  9863  9864  9865  9866  9867  9868  \n",
              "0         0     0     0     0     0     0     0     0     0     0  \n",
              "1         0     0     0     0     0     0     0     0     0     0  \n",
              "2         0     0     0     0     0     0     0     0     0     0  \n",
              "3         0     0     0     0     0     0     0     0     0     0  \n",
              "4         0     0     0     0     0     0     0     0     0     0  \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "27638     0     0     0     0     0     0     0     0     0     0  \n",
              "27639     0     0     0     0     0     0     0     0     0     0  \n",
              "27640     0     0     0     0     0     0     0     0     0     0  \n",
              "27641     0     0     0     0     0     0     0     0     0     0  \n",
              "27642     0     0     0     0     0     0     0     0     0     0  \n",
              "\n",
              "[27643 rows x 9876 columns]"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset, testset = input(stream=False)\n",
        "preprocessor = FeaturePreprocessor(get_title=False)\n",
        "\n",
        "dataset.x = preprocessor.fit_transform(dataset.x)\n",
        "testset.x = preprocessor.transform(testset.x)\n",
        "dataset.y = dataset.y.replace(-1, 0)\n",
        "\n",
        "dataset.x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1610a0f47dae47439490b1f976a6b880",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on fold [0/4]\n",
            "\n",
            "bestTest = 0.597732947\n",
            "bestIteration = 435\n",
            "\n",
            "Training on fold [1/4]\n",
            "\n",
            "bestTest = 0.592421129\n",
            "bestIteration = 256\n",
            "\n",
            "Training on fold [2/4]\n",
            "\n",
            "bestTest = 0.5908164855\n",
            "bestIteration = 30\n",
            "\n",
            "Training on fold [3/4]\n",
            "\n",
            "bestTest = 0.6002207441\n",
            "bestIteration = 457\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# CatBoost\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    dataset.x, dataset.y, test_size=0.2, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "\n",
        "cat_features = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "pool = cb.Pool(dataset.x, dataset.y, cat_features=cat_features)\n",
        "\n",
        "cb_params = {\n",
        "    \"l2_leaf_reg\": 2.5,\n",
        "    \"random_strength\": 0.8,\n",
        "}\n",
        "\n",
        "cb_params = {\n",
        "    \"depth\": 10,\n",
        "    \"learning_rate\": 0.04,\n",
        "    \"l2_leaf_reg\": 3,\n",
        "    \"loss_function\": \"CrossEntropy\",\n",
        "    \"border_count\": 254,\n",
        "    \"od_pval\": 0.01,\n",
        "    \"od_type\": \"IncToDec\",\n",
        "    \"thread_count\": -1,\n",
        "    \"random_strength\": 1.2,\n",
        "    \"eval_metric\": \"AUC\",\n",
        "    \"num_trees\": 2200,\n",
        "    \"random_state\": RANDOM_STATE,\n",
        "    \"bootstrap_type\": \"MVS\",\n",
        "    \"mvs_reg\": 0.3,\n",
        "    # \"bagging_temperature\": 1.2,\n",
        "}\n",
        "\n",
        "cv_result = cb.cv(\n",
        "    pool,\n",
        "    cb_params,\n",
        "    num_boost_round=2200,\n",
        "    fold_count=4,\n",
        "    plot=True,\n",
        "    verbose=False,\n",
        "    seed=RANDOM_STATE,\n",
        "    return_models=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<catboost.core.CatBoost at 0x7f903792fb20>,\n",
              " <catboost.core.CatBoost at 0x7f903792feb0>,\n",
              " <catboost.core.CatBoost at 0x7f903792fa30>,\n",
              " <catboost.core.CatBoost at 0x7f90380f6950>]"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_result[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test AUC: 0.5919 +/- 0.0047\n"
          ]
        }
      ],
      "source": [
        "test_mean = cv_result[0][\"test-AUC-mean\"].mean()\n",
        "test_std = cv_result[0][\"test-AUC-std\"].mean()\n",
        "\n",
        "print(f\"Test AUC: {test_mean:.4f} +/- {test_std:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = cv_result[1][3]\n",
        "val_score = roc_auc_score(y_val, clf.predict(x_val))\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_filename = f\"cb_{timestamp}_{val_score*10000:.0f}.cbm\"\n",
        "save_path = os.path.join(MODEL_SAVE_DIR, model_filename)\n",
        "\n",
        "print(f\"Validation AUC: {val_score:.4f}\")\n",
        "\n",
        "clf.save_model(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "ename": "CatBoostError",
          "evalue": "Exactly one of fname/stream/blob arguments mustn't be None",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m/home/matcha0714/sclab-nas_home/project/1121_DL_Competition/competition1/main.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsclab-64_%284090x2%29/home/matcha0714/sclab-nas_home/project/1121_DL_Competition/competition1/main.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m cb\u001b[39m.\u001b[39;49mCatBoost\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsclab-64_%284090x2%29/home/matcha0714/sclab-nas_home/project/1121_DL_Competition/competition1/main.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/home/matcha0714/sclab-nas_home/project/1121_DL_Competition/competition1/model_saves/cb_20231018-172425_5746.cbm\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsclab-64_%284090x2%29/home/matcha0714/sclab-nas_home/project/1121_DL_Competition/competition1/main.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
            "File \u001b[0;32m~/conda/envs/DL_Comp/lib/python3.10/site-packages/catboost/core.py:3322\u001b[0m, in \u001b[0;36mCatBoost.load_model\u001b[0;34m(self, fname, format, stream, blob)\u001b[0m\n\u001b[1;32m   3313\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3314\u001b[0m \u001b[39mLoad model from a file, stream or blob.\u001b[39;00m\n\u001b[1;32m   3315\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3319\u001b[0m \u001b[39m    Input file name.\u001b[39;00m\n\u001b[1;32m   3320\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3321\u001b[0m \u001b[39mif\u001b[39;00m (fname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39m+\u001b[39m (stream \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39m+\u001b[39m (blob \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 3322\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39mExactly one of fname/stream/blob arguments mustn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3324\u001b[0m \u001b[39mif\u001b[39;00m fname \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_model(fname, \u001b[39mformat\u001b[39m)\n",
            "\u001b[0;31mCatBoostError\u001b[0m: Exactly one of fname/stream/blob arguments mustn't be None"
          ]
        }
      ],
      "source": [
        "clf = cb.CatBoost.load_model(\n",
        "    \"/home/matcha0714/sclab-nas_home/project/1121_DL_Competition/competition1/model_saves/cb_20231018-172425_5746.cbm\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def xgb_training(x_train, y_train):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    model_filename = f\"xgb_{timestamp}.joblib\"\n",
        "    model_save_path = os.path.join(MODEL_SAVE_DIR, model_filename)\n",
        "\n",
        "    params = {\n",
        "        \"n_estimators\": 300,\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"colsample_bytree\": 0.3,\n",
        "        \"early_stopping_rounds\": 10,\n",
        "        \"random_state\": RANDOM_STATE,\n",
        "    }\n",
        "\n",
        "    params_distribution = {\n",
        "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
        "        \"max_depth\": [3, 5, 7, 9, 11],\n",
        "        \"alpha\": [0, 1, 3, 5, 7, 9, 10],\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "\n",
        "    cv = HalvingRandomSearchCV(\n",
        "        model,\n",
        "        params_distribution,\n",
        "        factor=3,\n",
        "        n_jobs=1,\n",
        "        scoring=\"roc_auc\",\n",
        "        random_state=RANDOM_STATE,\n",
        "    )\n",
        "    cv.fit(x_train, y_train)\n",
        "\n",
        "    print(f\"Best validation score: {cv.best_score_:.4f}\")\n",
        "\n",
        "    model = cv.best_estimator_\n",
        "    joblib.dump(model, model_save_path)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_params = FeatureParams(do_get_title=False)\n",
        "\n",
        "dataset, testset = input(stream=False)\n",
        "dataset.x = get_features(feature_params, dataset.x)\n",
        "dataset.y = dataset.y.replace(-1, 0)\n",
        "testset.x = get_features(feature_params, testset.x)\n",
        "\n",
        "xgb_model = xgb_training(dataset.x.values, dataset.y.values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LightGBM\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DL_Comp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
